# MCP LLM Server

Um servidor MCP (Model Context Protocol) em Python que oferece acesso unificado a mÃºltiplos provedores de LLM incluindo Claude AI, OpenAI, OpenRouter e Gemini.

## ğŸš€ CaracterÃ­sticas

- **MÃºltiplos Provedores**: Suporte para Claude AI, OpenAI, OpenRouter e Gemini
- **AutenticaÃ§Ã£o OAuth 2.0**: Sistema de autenticaÃ§Ã£o seguro
- **Arquitetura Modular**: FÃ¡cil de estender e manter
- **ConfiguraÃ§Ã£o FlexÃ­vel**: Suporte a mÃºltiplos formatos de configuraÃ§Ã£o
- **Logging Estruturado**: Sistema de logs detalhado para debugging
- **Tratamento de Erros**: RecuperaÃ§Ã£o automÃ¡tica e retry logic

## ğŸ“¦ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <repo-url>
cd mcp-llm-server

# Instale as dependÃªncias
pip install -r requirements.txt

# Configure as variÃ¡veis de ambiente
cp .env.example .env
# Edite .env com suas chaves de API
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# API Keys
OPENAI_API_KEY=sk-...
CLAUDE_API_KEY=sk-...
OPENROUTER_API_KEY=sk-...
GEMINI_API_KEY=...

# OAuth Configuration
OAUTH_CLIENT_ID=your-client-id
OAUTH_CLIENT_SECRET=your-client-secret
OAUTH_REDIRECT_URI=http://localhost:8080/callback

# Server Configuration
MCP_SERVER_NAME=llm-server
MCP_SERVER_VERSION=1.0.0
LOG_LEVEL=INFO
```

## ğŸ—ï¸ Arquitetura

```
src/mcp_llm_server/
â”œâ”€â”€ __init__.py           # InicializaÃ§Ã£o do pacote
â”œâ”€â”€ server.py             # Servidor MCP principal
â”œâ”€â”€ auth/                 # Sistema de autenticaÃ§Ã£o
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ oauth.py         # OAuth 2.0 implementation
â”‚   â””â”€â”€ token_manager.py # Gerenciamento de tokens
â”œâ”€â”€ clients/             # Clientes para LLMs
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py         # Cliente base abstrato
â”‚   â”œâ”€â”€ claude.py       # Cliente Claude AI
â”‚   â”œâ”€â”€ openai.py       # Cliente OpenAI
â”‚   â”œâ”€â”€ openrouter.py   # Cliente OpenRouter
â”‚   â””â”€â”€ gemini.py       # Cliente Gemini
â”œâ”€â”€ config/             # Gerenciamento de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py     # ConfiguraÃ§Ãµes do sistema
â”œâ”€â”€ tools/              # Ferramentas MCP
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chat.py         # Ferramenta de chat
â”‚   â”œâ”€â”€ completion.py   # Ferramenta de completion
â”‚   â””â”€â”€ model_info.py   # InformaÃ§Ãµes dos modelos
â””â”€â”€ utils/              # UtilitÃ¡rios
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ logging.py      # Sistema de logging
    â””â”€â”€ exceptions.py   # ExceÃ§Ãµes customizadas
```

## ğŸ”Œ Uso com Claude Code

```bash
# Adicionar o servidor MCP
claude mcp add llm-server "python -m mcp_llm_server"

# Ou com configuraÃ§Ã£o especÃ­fica
claude mcp add -e OPENAI_API_KEY=sk-... llm-server "python -m mcp_llm_server"
```

## ğŸ› ï¸ Desenvolvimento

```bash
# Executar testes
pytest tests/

# Executar com debugging
python -m mcp_llm_server --debug

# Executar linting
flake8 src/
black src/
```

## ğŸ“š Exemplos

Veja a pasta `examples/` para exemplos de uso detalhados.

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.